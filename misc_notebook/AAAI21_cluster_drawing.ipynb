{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# tf.get_logger().setLevel('INFO')\n",
    "import importlib\n",
    "\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_data_mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14c5863b558e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# base_pca = PCA(n_components=2).fit_transform(base)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# rnd_per = np.array(base_pca)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_data_mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0msaved_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_data_mnist'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.pyplot import scatter\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def rand_jitter(arr):\n",
    "    stdev = .03*(max(arr)-min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "\n",
    "def y_jitter(arr):\n",
    "    stdev = .08 * (max(arr) - min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "\n",
    "def jitter(x, y, s=20, c='b', marker='o', cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, hold=None, **kwargs):\n",
    "    return scatter(rand_jitter(x), y_jitter(y),\\\n",
    "                   s=s, c=c, marker=marker, cmap=cmap, norm=norm, \\\n",
    "                   vmin=vmin, vmax=vmax, alpha=alpha, linewidths=linewidths, \\\n",
    "                   verts=verts)\n",
    "\n",
    "\n",
    "# np.random.seed(42 * 100 + 4321567)\n",
    "# base_pca = PCA(n_components=2).fit_transform(base)\n",
    "# rnd_per = np.array(base_pca)\n",
    "with open('saved_data_mnist', 'rb') as f:\n",
    "    saved_result = pickle.load(f)\n",
    "\n",
    "curr_round = saved_result[0]    \n",
    "x = curr_round['x']\n",
    "y = curr_round['y']\n",
    "\n",
    "# kmeans = KMeans(init='k-means++' , n_clusters=4, n_init=10, max_iter=100)\n",
    "# kmeans.fit(rnd_per)\n",
    "\n",
    "# classes = kmeans.predict(rnd_per)\n",
    "classes = curr_round['class']\n",
    "print(classes)\n",
    "\n",
    "jitter(x, y, c=classes)\n",
    "plt.savefig(\"cluster_plot.png\",  dpi=300, transparent=True)\n",
    "# plt.scatter(x, y, c=classes, marker=\"o\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_clients(dataset, model=None, use_val_set=False):\n",
    "    eval_set = 'test' if not use_val_set else 'val'\n",
    "    train_data_dir = os.path.join('data', dataset, 'data', 'train')\n",
    "    test_data_dir = os.path.join('data', dataset, 'data', eval_set)\n",
    "\n",
    "    users, groups, train_data, test_data = read_data(train_data_dir, test_data_dir)\n",
    "    if len(groups) == 0:\n",
    "        groups = [[] for _ in users]    \n",
    "    clients = [Client(u, g, train_data[u], test_data[u], model) for u, g in zip(users, groups)]\n",
    "\n",
    "    return clients, train_data, test_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################## feminst.cnn##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '%s.%s' % (\"femnist\", \"cnn\")\n",
    "print('############################## %s ##############################' % model_path)\n",
    "mod = importlib.import_module(model_path)\n",
    "ClientModel = getattr(mod, 'ClientModel')\n",
    "\n",
    "path = \"../fedmc/models/checkpoints/femnist\"\n",
    "K = 4\n",
    "lr = 0.01\n",
    "num_class = 62\n",
    "\n",
    "model_initlization = ClientModel(123456, lr, num_class)\n",
    "clients, train_data, test_data = setup_clients(\"femnist\", model_initlization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################## celeba.cnn##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '%s.%s' % (\"celeba\", \"cnn\")\n",
    "print('############################## %s ##############################' % model_path)\n",
    "mod = importlib.import_module(model_path)\n",
    "ClientModel = getattr(mod, 'ClientModel')\n",
    "\n",
    "path = \"../fedmc/models/checkpoints/celeba\"\n",
    "K = 3\n",
    "lr = 0.1\n",
    "num_class = 2\n",
    "\n",
    "model_initlization = ClientModel(654321, lr, num_class)\n",
    "clients, train_data, test_data = setup_clients(\"celeba\", model_initlization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../fedmc/models/checkpoints/femnist/K-4/K4-C1.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../fedmc/models/checkpoints/femnist/K-4/K4-C2.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../fedmc/models/checkpoints/femnist/K-4/K4-C3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../fedmc/models/checkpoints/femnist/K-4/K4-C4.ckpt\n"
     ]
    }
   ],
   "source": [
    "K = 4\n",
    "ens_models = []\n",
    "for i in range(K):\n",
    "    model = ClientModel(random.randint(1, 10000), lr, num_class)\n",
    "    model.load_ckp(os.path.join(path, \"K-{}\".format(K), \"K{}-C{}.ckpt\".format(K, i+1)))\n",
    "    ens_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref>, <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'conv2d_1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'conv2d_2/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'conv2d_3/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'batch_normalization_3/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'dense/kernel:0' shape=(1152, 2) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "# with ens_models[0].graph.as_default():\n",
    "#     print(str(tf.trainable_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "VARIABLE_KEY = \"dense_1/kernel\"\n",
    "\n",
    "def make_x_base(m_idx, c_size):\n",
    "    \n",
    "    base = list()\n",
    "    key_dict = {}\n",
    "    ac_list = [0] * c_size\n",
    "    id_list = [''] * c_size\n",
    "    lvl_list = [0] * c_size\n",
    "#     tmp_model = ClientModel(123456, lr, num_class)\n",
    "#     tmp_model.load_ckp(\"./init/rnd_model.ckpt\")\n",
    "    for x, client in enumerate(clients[0:c_size]):\n",
    "        client.model.set_params(ens_models[m_idx].get_params())\n",
    "        train(client.model, client)\n",
    "        accuracy = model_initlization.test(client.eval_data)[ACCURACY_KEY]\n",
    "        id_list[x] = str(client.id) \n",
    "        ac_list[x] = accuracy\n",
    "        if (accuracy <= 0.5):\n",
    "            lvl_list[x] = 1\n",
    "        elif (accuracy <1.0):\n",
    "            lvl_list[x] = 2\n",
    "                \n",
    "        #print(\"accuracy: % +.2f\" % accuracy)\n",
    "        with client.model.graph.as_default():\n",
    "            all_vars = tf.trainable_variables()\n",
    "            for v in all_vars:\n",
    "                key_dict[v.name] = v.eval(client.model.sess)\n",
    "            l_w = key_dict[VARIABLE_KEY + \":0\"].reshape(1, -1)\n",
    "            base.extend(l_w)\n",
    "    print(\"mean:\", np.mean(ac_list))\n",
    "    print(\"std:\", np.std(ac_list, axis=0))\n",
    "    df = pd.DataFrame(zip(id_list, ac_list, lvl_list), columns=[\"id\", \"acc\", \"lvl\"])\n",
    "    return base, df\n",
    "\n",
    "def train(model, client):\n",
    "        _, params = model.train(train_data[client.id], num_epochs=10, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8595676871163167\n",
      "std: 0.05714244894871851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "base, df = make_x_base(0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8), dpi=200)\n",
    "# N = 100\n",
    "# r0 = 0.6\n",
    "# x = 0.9 * np.random.rand(N)\n",
    "# y = 0.9 * np.random.rand(N)\n",
    "# area = (20 * np.random.rand(N))**2  # 0 to 10 point radii\n",
    "# c = np.sqrt(area)\n",
    "# r = np.sqrt(x ** 2 + y ** 2)\n",
    "# area1 = np.ma.masked_where(r < r0, area)\n",
    "# area2 = np.ma.masked_where(r >= r0, area)\n",
    "# plt.scatter(x, y, s=area1, marker='^', c=c)\n",
    "# plt.scatter(x, y, s=area2, marker='o', c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
