{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d24c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 44em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739bb88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting robust_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile robust_main.py\n",
    "import numpy as np\n",
    "import random\n",
    "from math import modf, log\n",
    "from scipy.spatial.distance import cdist\n",
    "from kbmom.kmedianpp import euclidean_distances, kmedianpp_init\n",
    "\n",
    "class KbMOM:\n",
    "    \n",
    "    def __init__(self,X,K,nbr_blocks,coef_ech = 6,max_iter = 40,outliers = None, confidence = 0.95, threshold = 0.001,quantile   = 0.5,initial_centers = None,init_type ='km++',averaging_strategy='cumul', n_layers = 1):\n",
    "        '''\n",
    "        # X             : numpy array = contains the data we want to cluster\n",
    "        # K             : number of clusters\n",
    "        # nbr_blocks    : number of blocks to create in init and loop\n",
    "        # coef_ech      : NUMBER of data in each block and cluster\n",
    "        # quantile      : quantile to keep for the empirical risk; by default the median\n",
    "        # max_iter      : number of iterations of the algorithm\n",
    "        # max_iter_init : number of iterations to run for the kmeans in the initilization procedure\n",
    "        # kmeanspp      : boolean. If true then init by kmeanspp else kmedianpp\n",
    "        # outliers      : number of supposed outliers\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        # the structure of X_blocks and centers needs to to be modified.\n",
    "        # they need to store the whole parameters of a model.\n",
    "        # but when computing distance or predicting, just use the last\n",
    "        # layer of the parameters.\n",
    "        # to faciliate this computing, just added a function last_layer\n",
    "        \n",
    "        # Thus each item in X is a [n_layers] model, X is by number of clients array of numpy data.\n",
    "        '''\n",
    "        \n",
    "        # given element\n",
    "        self.X          = None\n",
    "        self.K          = K\n",
    "        self.max_iter   = max_iter\n",
    "        self.n, self.p  = len(X), X[0][n_layers].shape[0] * X[0][n_layers].shape[1]\n",
    "        self.quantile   = quantile\n",
    "        self.coef_ech   = coef_ech\n",
    "        self.B          = nbr_blocks\n",
    "        self.alpha      = 1 - confidence\n",
    "        self.threshold  = threshold\n",
    "        self.init_type  = init_type\n",
    "        self.averaging_strategy = averaging_strategy\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        \n",
    "        # Test some given values\n",
    "        if outliers is not None:\n",
    "            self.outliers = outliers\n",
    "            t_sup = self.bloc_size(self.n,self.outliers)\n",
    "            if self.coef_ech > t_sup:\n",
    "                self.coef_ech  = max((t_sup-5),1)\n",
    "                self.coef_ech  = int(round(self.coef_ech))\n",
    "                print('warning:: the size of blocks has been computed according to the breakdown point theory')\n",
    "\n",
    "            B_sup = self.bloc_nb(self.n,self.outliers,b_size=self.coef_ech,alpha=self.alpha)\n",
    "            if self.B < B_sup :\n",
    "                self.B     = round(B_sup) + 10\n",
    "                self.B     = int(self.B)\n",
    "                print('warning:: the number of blocks has been computed according to the breakdown point theory')\n",
    "        \n",
    "        # Deal with exceptions:\n",
    "        if self.coef_ech <= self.K:\n",
    "            self.coef_ech = 2*self.K\n",
    "        \n",
    "        # internal element initialization\n",
    "        self.score         = np.ones((self.n,))\n",
    "        \n",
    "        if isinstance(initial_centers,np.ndarray):\n",
    "            self.centers = initial_centers\n",
    "        else:\n",
    "            self.centers = 0\n",
    "            \n",
    "        self.block_empirical_risk = []\n",
    "        self.median_block_centers = []\n",
    "        self.empirical_risk = []\n",
    "        self.iter           = 1\n",
    "        self.warnings       = 'None'\n",
    "    \n",
    "    def init_centers_function(self,X,idx_blocks):\n",
    "        '''\n",
    "        # Initialisation function: create nbr_blocks blocks, initialize with a kmeans++, \n",
    "        retrieve the index of the median block and its empirical risk value\n",
    "        \n",
    "         ``` prms ```\n",
    "        . X          : numpy array of data\n",
    "        . idx_blocks : list of indices contained in the B blocks\n",
    "        '''\n",
    "        \n",
    "        # Blocks creation\n",
    "        size_of_blocks = self.coef_ech\n",
    "        \n",
    "        block_inertia = []\n",
    "        init_centers  = []\n",
    "        if self.init_type=='km++':\n",
    "            # instanciation of kmeans++\n",
    "            x_squared = X**2\n",
    "            x_squared_norms = x_squared.sum(axis=1)\n",
    "        \n",
    "            for idx_ in idx_blocks: \n",
    "                init_centers_ = kmedianpp_init(X[idx_,:], self.K, x_squared_norms[idx_], n_local_trials=None, square=True)\n",
    "                init_centers.append(init_centers_)\n",
    "                block_inertia.append(self.inertia_function(idx_,init_centers_))\n",
    "        else:\n",
    "            for idx_ in idx_blocks: \n",
    "                init_centers_ = self.random_init([X[i] for i in idx_])\n",
    "                init_centers.append(init_centers_)\n",
    "                block_inertia.append(self.inertia_function(idx_,init_centers_))\n",
    "            \n",
    "        median_risk = sorted(block_inertia)[round(self.quantile*len(block_inertia))]\n",
    "\n",
    "        # Select the Q-quantile bloc\n",
    "        id_median = block_inertia.index(median_risk)\n",
    "        \n",
    "        # init centers\n",
    "        self.centers = init_centers[id_median]\n",
    "        \n",
    "        return(id_median,median_risk)\n",
    "    \n",
    "    def random_init(self,dataset):\n",
    "        rnd_ =  np.random.choice(len(dataset), self.K)\n",
    "        s = [dataset[i] for i in rnd_]\n",
    "        return s\n",
    "        \n",
    "    def sampling_all_blocks_function(self):#,nbr_blocks,weighted_point,cluster_sizes):\n",
    "        '''\n",
    "        # Function which creates nbr_blocks blocks based on self.coef_ech and self.B\n",
    "        '''\n",
    "        blocks = [random.choices(np.arange(self.n),k = self.coef_ech) for i in range(self.B)]\n",
    "        return(blocks)\n",
    "    \n",
    "    \n",
    "    def inertia_function(self,idx_block,centroids = None):\n",
    "        '''\n",
    "        # Function which computes empirical risk per block\n",
    "        \n",
    "         ``` prms ```\n",
    "        . X          : numpy array of data\n",
    "        . idx_block  : list of indices contained in the B blocks\n",
    "        . centroids  : if not None get the centers from kmeans++ initialisation\n",
    "        '''\n",
    "        if not isinstance(centroids,list):\n",
    "            centroids = self.centers\n",
    "        \n",
    "#         print(\"The block contains:[\",  idx_block ,\"]\")\n",
    "        X_block           = [self.X[i] for i in idx_block]\n",
    "        nearest_centroid  = self.fed_dist(X_block,centroids,'sqeuclidean').argmin(axis=1)\n",
    "        \n",
    "        if len(set(nearest_centroid)) == self.K and sum(np.bincount(nearest_centroid) > 1) == self.K :\n",
    "            within_group_inertia = 0\n",
    "            for k,nc in enumerate(set(nearest_centroid)):\n",
    "                within_group_inertia += self.inertia_per_cluster(X_block, nearest_centroid, nc)\n",
    "            \n",
    "            return(within_group_inertia/len(idx_block))\n",
    "        else:\n",
    "            return(-1)\n",
    "     \n",
    "            \n",
    "    def median_risk_function(self,X,blocks):\n",
    "        '''\n",
    "        # Function which computes the sum of all within variances and return the index of the median block\n",
    "        and its empirical risk\n",
    "        \n",
    "        ```parameters ```       \n",
    "            . blocks     : list of indices forming the blocks\n",
    "            . X          : matrix of datapoints\n",
    "        '''\n",
    "        \n",
    "        block_inertia = list(map(self.inertia_function, blocks))\n",
    "            \n",
    "        nb_nonvalide_blocks = sum(np.array(block_inertia) == -1)\n",
    "        nb_valide_blocks    = int(self.B - nb_nonvalide_blocks)\n",
    "        \n",
    "        if nb_nonvalide_blocks != self.B:\n",
    "            \n",
    "            median_risk = sorted(block_inertia)[nb_nonvalide_blocks:][round(self.quantile*nb_valide_blocks)]\n",
    "            \n",
    "            # Select the Q-quantile bloc\n",
    "            id_median = block_inertia.index(median_risk)\n",
    "            return(id_median,median_risk)\n",
    "    \n",
    "        else:\n",
    "            return(None,None)\n",
    "        \n",
    "    def medianblock_centers_function(self,X,id_median,blocks):\n",
    "        '''\n",
    "        #compute the barycenter of each cluster in the median block\n",
    "        \n",
    "         ``` prms ```\n",
    "         . blocks     : list of indices forming the blocks\n",
    "         . X          : matrix of datapoints\n",
    "         . id_median  : index of the median block\n",
    "        '''\n",
    "        X_block           = [X[i] for i in blocks[id_median]]\n",
    "        distances         = self.fed_dist(X_block,self.centers,'sqeuclidean')\n",
    "        nearest_centroid  = distances.argmin(axis=1)\n",
    " \n",
    "        print(\"len of nearest centroid: \", len(set(nearest_centroid)))\n",
    "        centers_ = [0] * len(set(nearest_centroid))\n",
    "        for k,nc in enumerate(set(nearest_centroid)):\n",
    "            cl_block = []\n",
    "            for i,v  in  enumerate( blocks[id_median] ) :\n",
    "                if nearest_centroid[i] == nc:\n",
    "                    cl_block.append(v)\n",
    "            _, upd = self.E_func(self.centers[nc], cl_block)\n",
    "            centers_[k] = self.M_func()\n",
    "            cnt = 0\n",
    "            for i, v in enumerate( blocks[id_median] ):\n",
    "                if nearest_centroid[i] == nc:\n",
    "                    self.X[v] = upd[cnt][1] # update is a tuple which return by E_func, the 0 is a number of samples, the 1 is model\n",
    "                    cnt += 1\n",
    "                             \n",
    "        self.centers = centers_\n",
    "        return(self)\n",
    "    \n",
    "    \n",
    "    def weigthingscheme(self,median_block):\n",
    "        '''\n",
    "        Function which computes data depth\n",
    "        \n",
    "        ``` prms ```\n",
    "        . median_block: list containing the indices of data in the median block\n",
    "        \n",
    "        ''' \n",
    "        for idk in median_block:\n",
    "            self.score[idk] += 1\n",
    "        return(self)\n",
    "    \n",
    "    \n",
    "    def fit(self,X):\n",
    "        '''\n",
    "        # Main loop of the K-bmom algorithm:\n",
    "        \n",
    "         ``` prms ```\n",
    "        . X          : matrix of datapoints \n",
    "        '''\n",
    "        self.X = X\n",
    "        # initialisation step\n",
    "        if not isinstance(self.centers,np.ndarray):\n",
    "            idx_block = self.sampling_all_blocks_function()\n",
    "            id_median , median_risk_ = self.init_centers_function(X,idx_block)\n",
    "\n",
    "            self.block_empirical_risk.append(median_risk_)\n",
    "            self.medianblock_centers_function(X, id_median,idx_block)\n",
    "            self.median_block_centers.append(self.centers)\n",
    "            self.empirical_risk.append(sum(self.fed_dist(self.X, self.centers,'sqeuclidean').min(axis=1))/self.n)\n",
    "            self.weigthingscheme(median_block=idx_block[id_median])\n",
    "        \n",
    "        if self.averaging_strategy == 'cumul':\n",
    "            cumul_centers_ = self.centers\n",
    "        \n",
    "        # Main Loop - fitting process\n",
    "        if (self.max_iter == 0):\n",
    "            condition = False\n",
    "        else:\n",
    "            condition = True\n",
    "       \n",
    "        while condition:\n",
    "            print('--- Round %d of %d: Training %d Clients ---' % (self.iter+1, self.max_iter, self.coef_ech))\n",
    "            # sampling\n",
    "            idx_block = self.sampling_all_blocks_function()\n",
    "            \n",
    "            # Compute empirical risk for all blocks and select the empirical-block\n",
    "            id_median , median_risk_ = self.median_risk_function(self.X,idx_block)\n",
    "            \n",
    "            # If blocks are undefined, then restarting strategy\n",
    "            loop_within = 0\n",
    "            while (id_median == None) and loop_within < 10:\n",
    "                idx_block = self.sampling_all_blocks_function()\n",
    "                id_median , median_risk_ = self.init_centers_function(self.X,idx_block)\n",
    "                cumul_centers_  = np.zeros((self.K,self.p))\n",
    "                self.warnings = 'restart'\n",
    "                loop_within += 1\n",
    "            \n",
    "            if id_median == None:\n",
    "                self.iter = self.max_iter\n",
    "                self.warnings = 'algorithm did not converge'\n",
    "                condition = False\n",
    "                \n",
    "            else:\n",
    "                # update all parameters\n",
    "                self.block_empirical_risk.append(median_risk_)\n",
    "                self.medianblock_centers_function(self.X,id_median,idx_block)\n",
    "                self.median_block_centers.append(self.centers)\n",
    "                self.empirical_risk.append(sum(self.fed_dist(self.X,self.centers,'sqeuclidean').min(axis=1))/self.n)\n",
    "                self.weigthingscheme(median_block=idx_block[id_median])\n",
    "\n",
    "#                 if self.averaging_strategy == 'cumul' and self.iter > (self.max_iter - 10):\n",
    "#                     decay = self.max_iter - 10\n",
    "#                     #current_centers = self.pivot(self.centers,cumul_centers_)\n",
    "#                     cumul_centers_  = (self.centers / (self.iter - decay)) + (self.iter-decay - 1)/(self.iter - decay) * cumul_centers_\n",
    "#                     self.centers = cumul_centers_\n",
    "\n",
    "                self.iter += 1\n",
    "                if self.iter>=self.max_iter:\n",
    "                    condition = False\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    \n",
    "    def predict(self,X):\n",
    "        '''\n",
    "        Function which computes the partition based on the centroids of Median Block \n",
    "        '''\n",
    "        D_nk = self.fed_dist(X,self.centers,'sqeuclidean')\n",
    "        return(D_nk.argmin(axis=1))\n",
    "    \n",
    "\n",
    "    def bloc_size(self,n_sample,n_outliers):\n",
    "        '''\n",
    "        Function which fits the maximum size of blocks before a the breakpoint\n",
    "        ```prms```\n",
    "        n_sample: nb of data\n",
    "        n_outlier: nb of outliers\n",
    "        '''\n",
    "        return(log(2.)/log(1/(1- (n_outliers/n_sample))))\n",
    "\n",
    "\n",
    "    def bloc_nb(self,n_sample,n_outliers,b_size=None,alpha=0.05):\n",
    "        '''\n",
    "        Function which fits the minimum nb of blocks for a given size t before a the breakpoint\n",
    "        ```prms```\n",
    "        n_sample: nb of data\n",
    "        n_outlier: nb of outliers\n",
    "        b_size = bloc_size\n",
    "        alpha : threshold confiance\n",
    "        '''\n",
    "        if n_outliers/n_sample >= 0.5:\n",
    "            print('too much noise')\n",
    "            return()\n",
    "        elif b_size == None:\n",
    "            t = bloc_size(n_sample,n_outliers)\n",
    "            return(log(1/alpha) / (2* ((1-n_outliers/n_sample)**t - 1/2)**2))\n",
    "        else:\n",
    "            t = b_size\n",
    "            return(log(1/alpha) / (2* ((1-n_outliers/n_sample)**t - 1/2)**2))\n",
    "   \n",
    "    def stopping_crit(self,risk_median):\n",
    "        risk_ = risk_median[::-1][:3]\n",
    "        den = (risk_[2]-risk_[1])-(risk_[1]-risk_[0])\n",
    "        Ax = risk_[2] - (risk_[2]-risk_[1])**2/den\n",
    "        return(Ax)\n",
    "    \n",
    "    def stopping_crit_GMM(self,risk_median):\n",
    "        risk_ = risk_median[::-1][:3]\n",
    "        Aq   = (risk_[0] - risk_[1])/(risk_[1] - risk_[2])\n",
    "        \n",
    "        Rinf = risk_[1] + 1/(1-Aq)*(risk_[0] - risk_[1])\n",
    "        return(Rinf)\n",
    "        \n",
    "    def pivot(self,mu1,mu2):\n",
    "        error    = cdist(mu1,mu2).argmin(axis=1)\n",
    "        pivot_mu = np.zeros((self.K,self.p))\n",
    "        for i,j in enumerate(error):\n",
    "            pivot_mu[i,:] = mu1[j,:]\n",
    "        return(pivot_mu)\n",
    "    \n",
    "    def set_E_func(self, func):\n",
    "        self.E_func  = func\n",
    "        \n",
    "    def set_M_func(self, func):\n",
    "        self.M_func = func\n",
    "        \n",
    "    def last_layer(self, X_list):\n",
    "        return [x[self.n_layers] for x in X_list]\n",
    "    \n",
    "    def fed_dist(self, Xa, Xb, method = 'sqeuclidean'):\n",
    "        xa_transformed = self.last_layer(Xa)\n",
    "        xb_transformed = self.last_layer(Xb)\n",
    "        \n",
    "        xa = list(map(lambda x: x.flatten(), xa_transformed))\n",
    "        xb = list(map(lambda x: x.flatten(), xb_transformed))\n",
    "            \n",
    "        return cdist(np.array(xa), np.array(xb), method)\n",
    "    \n",
    "    def inertia_per_cluster(self, X_block, nearest_centroids, nc):\n",
    "        clster = list()\n",
    "        tran_x_block = self.last_layer(X_block)\n",
    "        for i, xb in enumerate(tran_x_block):\n",
    "            if nearest_centroids[i] == nc:\n",
    "                clster.append(xb.flatten())\n",
    "                \n",
    "        centers_ = np.array(clster).mean(axis = 0).reshape(1, -1)\n",
    "        return cdist(np.array(clster), centers_,'sqeuclidean').sum()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b4cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fedrobust.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fedrobust.py\n",
    "# note to audience, fedrobust is based on the work of Median-of-means K-means,\n",
    "# author is Camille Saumard, his email is camille.brunet@gmail.com\n",
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from math import modf, log\n",
    "from scipy.spatial.distance import cdist\n",
    "from kbmom.kmedianpp import euclidean_distances, kmedianpp_init\n",
    "\n",
    "# tensorflow is required for our experiment, please install tf 1.5 not 2\n",
    "import tensorflow as tf\n",
    "import metrics.writer as metrics_writer\n",
    "\n",
    "from baseline_constants import MAIN_PARAMS, MODEL_PARAMS\n",
    "from client import Client\n",
    "from server import Server, MDLpoisonServer\n",
    "from model import ServerModel\n",
    "from utils.constants import DATASETS\n",
    "from robust_main import KbMOM\n",
    "\n",
    "\n",
    "STAT_METRICS_PATH = 'metrics/stat_metrics.csv'\n",
    "SYS_METRICS_PATH = 'metrics/sys_metrics.csv'\n",
    "\n",
    "def online(clients):\n",
    "    \"\"\"We assume all users are always online.\"\"\"\n",
    "    return clients\n",
    "\n",
    "def save_model(server_model, dataset, model):\n",
    "    \"\"\"Saves the given server model on checkpoints/dataset/model.ckpt.\"\"\"\n",
    "    # Save server model\n",
    "    ckpt_path = os.path.join('checkpoints', dataset)\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        os.makedirs(ckpt_path)\n",
    "    save_path = server_model.save(os.path.join(ckpt_path, '%s.ckpt' % model))\n",
    "    print('Model saved in path: %s' % save_path)\n",
    "\n",
    "\n",
    "def print_metrics(metrics, weights):\n",
    "    ordered_weights = [weights[c] for c in sorted(weights)]\n",
    "    metric_names = metrics_writer.get_metrics_names(metrics)\n",
    "    for metric in metric_names:\n",
    "        ordered_metric = [metrics[c][metric] for c in sorted(metrics)]\n",
    "        print('%s: %g, 10th percentile: %g, 90th percentile %g' \\\n",
    "              % (metric,\n",
    "                 np.average(ordered_metric, weights=ordered_weights),\n",
    "                 np.percentile(ordered_metric, 10),\n",
    "                 np.percentile(ordered_metric, 90)))\n",
    "    fom = [metrics[c][metric_names[0]] for c in sorted(metrics)]\n",
    "    final = np.average(fom, weights=ordered_weights)\n",
    "    return final\n",
    "\n",
    "class Fedrobust_Trainer:\n",
    "    \n",
    "    def __init__(self, users, groups, train_data, test_data):\n",
    "        self.users = users\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.num_clients_per_round = 0\n",
    "        self.config = []\n",
    "        self.server = []\n",
    "        self.all_clients = []\n",
    "\n",
    "        \n",
    "    def model_config(self, config, dataset, my_model):   \n",
    "        shared_model = my_model\n",
    "        model_path = '%s/%s.py' % (dataset, shared_model)\n",
    "        if not os.path.exists(model_path):\n",
    "            print('Please specify a valid dataset and a valid model.')\n",
    "        model_path = '%s.%s' % (dataset, shared_model)\n",
    "\n",
    "        print('############################## %s ##############################' % model_path)\n",
    "        mod = importlib.import_module(model_path)\n",
    "        ClientModel = getattr(mod, 'ClientModel')  \n",
    "        # Suppress tf warnings\n",
    "        tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "        # Create 2 models\n",
    "        model_params = MODEL_PARAMS[model_path]\n",
    "        model_params_list = list(model_params)\n",
    "        model_params_list[0] = config[\"lr\"]\n",
    "        model_params = tuple(model_params_list)\n",
    "        tf.reset_default_graph()\n",
    "        client_model = ClientModel(config[\"seed\"], *model_params)\n",
    "\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # Create clients\n",
    "        _users = self.users\n",
    "        groups = [[] for _ in _users]\n",
    "        clients =  [Client(u, g, self.train_data[u], self.test_data[u], client_model) \\\n",
    "                    for u, g in zip(_users, groups)]\n",
    "        print('%d Clients in Total' % len(clients)) \n",
    "        self.all_clients = clients\n",
    "        \n",
    "        if config['poisoning'] == True:\n",
    "            num_agents = int(config[\"num_agents\"] * len(clients)) \n",
    "            clients_per_round = config[\"clients-per-round\"]            \n",
    "            server_ = MDLpoisonServer(client_model, clients, num_agents, clients_per_round)\n",
    "        else:\n",
    "            # Create server\n",
    "            server_ = Server(client_model)\n",
    "        self.Server = server_            \n",
    "        return clients, server_, client_model\n",
    "    \n",
    "    def fed_train(self, init_prms, client_in_block):\n",
    "        #server.select_clients(possible_clients, num_clients=len(possible_clients))\n",
    "        #c_ids, c_groups, c_num_samples = server.get_clients_info(None)\n",
    "        eval_every = self.config[\"eval-every\"]\n",
    "        epochs_per_round = self.config['epochs']\n",
    "        batch_size = self.config['batch-size']\n",
    "        print(\"Start training on these clients:\", client_in_block)\n",
    "        block_clients = [self.all_clients[i] for i in client_in_block]\n",
    "        sys_metrics, updates = self.Server.train_model(single_center=init_prms, num_epochs=epochs_per_round, batch_size=batch_size, minibatch=None, clients = block_clients, apply_prox=False)\n",
    "        return sys_metrics, updates\n",
    "         \n",
    "    def fed_update(self):\n",
    "        return self.Server.update_model_nowmode()\n",
    "    \n",
    "    def fed_test(self, nearest_centroid, robust):\n",
    "        accs_ = [0] * len(set(nearest_centroid))\n",
    "        for k,nc in enumerate(set(nearest_centroid)):\n",
    "            cl_within_clus = []\n",
    "            for i, v in enumerate(self.all_clients):\n",
    "                if nearest_centroid[i] == nc:\n",
    "                    cl_within_clus.append(self.all_clients[i])\n",
    "            self.Server.model = robust.centers[nc]\n",
    "            stat_metrics = self.Server.test_model(cl_within_clus)\n",
    "            c_ids, c_groups, c_num_samples = self.Server.get_clients_info(cl_within_clus)\n",
    "            accs_[k] = print_metrics(stat_metrics, c_num_samples)\n",
    "        print(\"--- Acc: \",  np.average(accs_), \" ---\")\n",
    "    \n",
    "    def begins(self, config, args):\n",
    "        \n",
    "        def shout(text):\n",
    "            return text.upper()\n",
    "        \n",
    "        clients, server, client_model = self.model_config(config, args.dataset, 'cnn')  \n",
    "        \n",
    "        K = config[\"num-clusters\"]\n",
    "        num_rounds = config[\"num-rounds\"]\n",
    "        eval_every = config[\"eval-every\"]\n",
    "        epochs_per_round = config['epochs']\n",
    "        batch_size = config['batch-size']\n",
    "        clients_per_round = config[\"clients-per-round\"]\n",
    "        n_layers = config[args.dataset + \"-num-layers\"]\n",
    "        \n",
    "        all_ids, all_groups, all_num_samples = server.get_clients_info(clients)\n",
    "        # train all clients one round \n",
    "        _, tmp_data = server.train_model(None, 1, batch_size, None, clients, False)\n",
    "        all_cl_models = [x[1] for x in tmp_data ]\n",
    "        #print(\"the shape of a model is: \", len(all_cl_models[0][1]))\n",
    "        print(\"last layer of a model is:\", all_cl_models[0][n_layers].shape)\n",
    "            \n",
    "        # self.all_cl_models, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=0.7)\n",
    "        robust_helper = KbMOM(X = all_cl_models, K = K, nbr_blocks = 40, coef_ech = int(len(clients) * 0.3) , quantile=0.5, init_type='kmedianpp', n_layers = n_layers)\n",
    "        robust_helper.set_E_func(self.fed_train)\n",
    "        robust_helper.set_M_func(self.fed_update)\n",
    "        print(\"*** Robust algorithm training started ***\")\n",
    "        robust_helper.fit(all_cl_models)\n",
    "        #clients, server, client_model = self.model_config(config, args.dataset, 'cnn_prox')  \n",
    "        centroids = robust_helper.predict(all_cl_models)\n",
    "        self.fed_test(centroids, robust_helper)\n",
    "        return 0.5\n",
    "    \n",
    "    def ends(self):\n",
    "        print(\"experiment of Fed Robust is finished.\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613a6d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config rounds:  20\n",
      "config lr:  0.01\n",
      "config epochs:  3\n",
      "config clients per round:  40\n",
      "############################## femnist.cnn ##############################\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/fedrobust.py:87: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:24: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/femnist/cnn.py:43: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/femnist/cnn.py:52: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/jupyter/dev/mlenv/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/femnist/cnn.py:53: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/femnist/cnn.py:62: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/femnist/cnn.py:68: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/dev/mlenv/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:81: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/femnist/cnn.py:71: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:26: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2022-01-25 06:16:26.599920: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-01-25 06:16:26.600708: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-25 06:16:26.600734: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (david-08232021): /proc/driver/nvidia/version does not exist\n",
      "2022-01-25 06:16:26.624117: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-01-25 06:16:26.759785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100275000 Hz\n",
      "2022-01-25 06:16:26.761059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55df340d9150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-25 06:16:26.761095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/utils/tf_utils.py:33: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:32: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:34: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:35: The name tf.profiler.ProfileOptionBuilder is deprecated. Please use tf.compat.v1.profiler.ProfileOptionBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:36: The name tf.profiler.profile is deprecated. Please use tf.compat.v1.profiler.profile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/dev/mlenv/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.69m flops)\n",
      "  dense/kernel/Initializer/random_uniform (777.73k/1.56m flops)\n",
      "    dense/kernel/Initializer/random_uniform/mul (777.73k/777.73k flops)\n",
      "    dense/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  conv2d_1/kernel/Initializer/random_uniform (51.20k/102.40k flops)\n",
      "    conv2d_1/kernel/Initializer/random_uniform/mul (51.20k/51.20k flops)\n",
      "    conv2d_1/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  dense_1/kernel/Initializer/random_uniform (15.38k/30.75k flops)\n",
      "    dense_1/kernel/Initializer/random_uniform/mul (15.38k/15.38k flops)\n",
      "    dense_1/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  conv2d/kernel/Initializer/random_uniform (800/1.60k flops)\n",
      "    conv2d/kernel/Initializer/random_uniform/mul (800/800 flops)\n",
      "    conv2d/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)\n",
      "  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)\n",
      "  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:46: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "190 Clients in Total\n",
      "WARNING:tensorflow:From /home/jupyter/multi-center-fed-learning/models/model.py:42: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "last layer of a model is: (248, 62)\n",
      "*** Robust algorithm training started ***\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [20, 179, 26, 182, 89, 115, 80, 99, 84, 58, 19, 168, 122, 19, 41, 157, 131, 58, 28, 131, 27]\n",
      "Start training on these clients: [30, 42, 44, 35, 18, 45, 5, 6, 62, 0, 0]\n",
      "Start training on these clients: [186, 95, 92, 175, 185, 133, 86, 136, 174, 166, 123, 137, 139, 146, 162, 83, 141, 150, 130, 113, 166, 128, 189, 111, 95]\n",
      "**** Main Loop Fitting ****\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [159, 147, 1, 61, 53, 102, 87, 172, 149, 119, 117, 182, 121, 147, 54, 173, 122, 156, 23, 47, 12, 79, 52, 26, 32, 14, 121, 19, 143, 37, 164, 80, 81, 97, 173, 178, 22, 90, 143, 182, 101, 7, 142, 172, 34, 77, 163, 103]\n",
      "Start training on these clients: [18, 6, 35]\n",
      "Start training on these clients: [174, 128, 83, 150, 95, 128]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [85, 49, 126, 144, 26, 85, 170, 24, 90, 73, 42, 185, 130, 27, 149, 46, 7, 147, 77, 47, 185, 79, 183, 179, 187, 98, 141, 48, 145, 114, 32, 50, 10, 155, 85, 80, 165, 42, 170, 104, 179, 185, 177, 100, 74, 9, 130, 85, 149, 13, 188, 162]\n",
      "Start training on these clients: [35, 35]\n",
      "Start training on these clients: [95, 95, 174]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [0, 23, 120, 108, 140, 7, 24, 67, 71, 115, 124, 161, 42, 32, 141, 99, 86, 79, 20, 163, 181, 94, 158, 119, 80, 50, 58, 5, 138, 63, 55, 105, 81, 51, 168, 130, 38, 101, 135, 140, 1, 53, 164, 124, 144, 66, 107, 177, 14, 80, 183, 46]\n",
      "Start training on these clients: [6, 6]\n",
      "Start training on these clients: [83, 95, 83]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [49, 183, 182, 5, 183, 51, 13, 57, 159, 30, 66, 140, 117, 19, 7, 31, 184, 162, 111, 60, 131, 5, 162, 66, 66, 135, 121, 13, 87, 148, 76, 118, 38, 144, 91, 69, 147, 160, 187, 41, 130, 71, 90, 183, 160, 131, 118, 15, 46, 78, 138, 52]\n",
      "Start training on these clients: [35, 6]\n",
      "Start training on these clients: [150, 95, 174]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [26, 75, 146, 1, 119, 21, 108, 24, 130, 71, 188, 101, 34, 159, 97, 48, 55, 148, 156, 142, 69, 63, 96, 11, 67, 126, 107, 153, 64, 160, 62, 42, 143, 113, 56, 175, 57, 86, 27, 17, 167, 181, 96, 127, 2, 64, 26, 71, 176, 34, 159, 60, 70]\n",
      "Start training on these clients: [6, 6]\n",
      "Start training on these clients: [174, 83]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [173, 76, 41, 145, 15, 21, 137, 160, 92, 152, 21, 38, 26, 185, 43, 93, 38, 12, 41, 189, 123, 110, 80, 121, 45, 24, 37, 146, 30, 22, 187, 162, 39, 7, 144, 149, 1, 73, 7, 88, 121, 106, 123, 14, 158, 94, 123, 127, 103, 49, 178, 114, 147]\n",
      "Start training on these clients: [6, 35]\n",
      "Start training on these clients: [128, 174]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [127, 26, 89, 57, 124, 76, 2, 1, 84, 63, 176, 135, 12, 180, 142, 147, 102, 133, 39, 11, 141, 130, 172, 159, 1, 40, 180, 78, 96, 154, 160, 162, 25, 9, 108, 134, 142, 18, 14, 70, 46, 158, 73, 11, 53, 186, 156, 52, 43, 41]\n",
      "Start training on these clients: [6, 35]\n",
      "Start training on these clients: [128, 150, 83, 174, 174]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [143, 129, 165, 72, 18, 182, 87, 110, 168, 33, 36, 137, 21, 54, 56, 159, 136, 2, 125, 101, 148, 185, 167, 19, 99, 111, 65, 22, 113, 14, 75, 138, 47, 43, 156, 154, 119, 112, 125, 149, 60, 109, 169, 178, 136, 187, 69, 57, 179, 90, 104, 23]\n",
      "Start training on these clients: [35, 35]\n",
      "Start training on these clients: [83, 83, 128]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [166, 113, 100, 145, 62, 188, 139, 57, 172, 32, 38, 155, 140, 88, 21, 127, 107, 118, 101, 140, 24, 177, 142, 108, 149, 158, 123, 3, 167, 57, 33, 104, 164, 34, 77, 50, 28, 22, 57, 168, 8, 170, 50, 142, 104, 79, 113, 90, 188, 183, 161, 27, 138]\n",
      "Start training on these clients: [6, 6]\n",
      "Start training on these clients: [95, 150]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [48, 96, 51, 146, 157, 144, 108, 3, 67, 173, 87, 27, 185, 21, 64, 72, 118, 164, 178, 125, 176, 183, 111, 169, 43, 170, 116, 64, 10, 124, 114, 79, 68, 117, 42, 137, 145, 57, 134, 73, 10, 10, 99, 189, 143, 8, 114, 84, 111, 106]\n",
      "Start training on these clients: [6, 6, 35]\n",
      "Start training on these clients: [174, 95, 83, 95]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [104, 177, 91, 174, 159, 139, 162, 17, 13, 181, 13, 105, 113, 146, 83, 93, 153, 71, 28, 101, 102, 173, 69, 167, 145, 137, 178, 123, 166, 48, 105, 162]\n",
      "Start training on these clients: [66, 47, 63, 31, 14, 24, 3, 72, 43, 62, 15, 51, 21, 43, 21, 77, 35, 10, 5, 49]\n",
      "Start training on these clients: [0, 151, 74, 44, 29]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [139, 143, 134, 113, 110, 7, 9, 127, 118, 154, 182, 84, 81, 104, 41, 185, 164, 125, 136, 189, 13, 159, 107, 115, 149, 182, 26, 136, 172, 116, 84, 71, 26, 118, 95, 138, 105, 172, 79]\n",
      "Start training on these clients: [8, 11, 38, 49, 30, 37, 31, 60, 12]\n",
      "Start training on these clients: [29, 29, 20, 132, 61, 151, 122, 61, 74]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [70, 124, 58, 69, 96, 32, 139, 120, 123, 144, 100, 89, 23, 185, 100, 103, 126, 188, 34, 119, 34, 168, 152, 143, 19, 75, 147, 81, 58, 75, 69, 127, 13, 180, 148, 164, 80, 166]\n",
      "Start training on these clients: [36, 54, 72, 50, 11, 21, 72, 30, 12, 72, 65, 51]\n",
      "Start training on these clients: [132, 122, 16, 74, 16, 122, 122]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [175, 52, 180, 106, 187, 34, 129, 166, 168, 133, 79, 80, 152, 160, 135, 83, 70, 19, 138, 86, 137, 148, 188, 159, 89, 140, 156, 28, 119, 90, 71, 124, 101, 179, 69]\n",
      "Start training on these clients: [66, 40, 36, 45, 15, 49, 27, 66, 40, 55, 21, 38, 77, 76, 67, 18, 55, 18]\n",
      "Start training on these clients: [82, 171, 151, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [188, 177, 189, 185, 92, 84, 78, 33, 146, 177, 102, 87, 188, 174, 154, 174, 139, 119, 17, 131, 170, 184, 178, 81, 87, 23, 164, 85, 139, 9, 180, 152, 9, 128, 59, 143, 179, 103, 153, 139, 125, 84, 52, 87, 121, 188]\n",
      "Start training on these clients: [18, 65, 55, 11, 35, 72, 73, 46]\n",
      "Start training on these clients: [44, 74, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [124, 141, 140, 112, 80, 79, 135, 32, 129, 186, 186, 179, 80, 92, 123, 175, 90, 164, 23, 145, 175, 13, 155, 146, 7, 185, 68, 127, 93, 88, 115, 141, 189, 127, 101, 103, 165, 175, 143, 118, 22, 153, 89]\n",
      "Start training on these clients: [2, 50, 57, 10, 50, 54, 62, 47, 8, 42, 56, 35]\n",
      "Start training on these clients: [132, 44]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [157, 111, 95, 94, 163, 176, 127, 182, 184, 102, 158, 123, 175, 99, 115, 91, 180, 48, 186, 68, 186, 88, 114, 160, 117, 26, 118, 100, 113, 89, 164, 64, 131, 98, 169, 148, 101, 144, 173, 19, 59, 17, 182]\n",
      "Start training on these clients: [56, 45, 73, 12, 35, 27, 53, 49, 65, 14, 3]\n",
      "Start training on these clients: [4, 16, 20]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [117, 109, 158, 9, 126, 143, 159, 162, 145, 108, 83, 22, 186, 165, 81, 119, 159, 162, 101, 155, 150, 39, 85, 162, 97, 95, 89, 75, 90, 145, 145, 71, 143, 41, 180, 7, 147, 134, 86, 81, 139, 104]\n",
      "Start training on these clients: [53, 37, 14, 56, 3, 37, 40, 3, 54, 40, 24]\n",
      "Start training on these clients: [20, 151, 4, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [95, 119, 119, 131, 100, 159, 142, 149, 23, 154, 52, 156, 174, 7, 120, 86, 156, 107, 91, 101, 116, 140, 108, 182, 69, 157, 127, 71, 1, 141, 109, 188, 91, 116, 80, 127, 179, 160, 130, 90]\n",
      "Start training on these clients: [77, 2, 38, 57, 2, 42, 10, 27, 5, 21, 67, 51]\n",
      "Start training on these clients: [0, 151, 44, 0, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [102, 113, 9, 116, 135, 7, 64, 144, 177, 168, 173, 175, 69, 142, 129, 130, 97, 114, 188, 138, 23, 187, 116, 127, 158, 178, 167, 121, 154, 131, 150, 106, 111, 17, 189, 124, 13, 176, 97, 113, 160, 117, 141]\n",
      "Start training on these clients: [37, 54, 65, 12, 56, 27, 18, 8, 18]\n",
      "Start training on these clients: [132, 44, 44, 82, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [142, 59, 140, 161, 95, 22, 83, 89, 156, 116, 156, 99, 85, 134, 96, 112, 152, 9, 71, 184, 173, 149, 143, 58, 182, 84, 92, 188, 177, 70, 68, 34, 80, 163, 68, 59, 70, 41]\n",
      "Start training on these clients: [25, 54, 27, 49, 76, 76, 62, 65, 35, 8, 62, 8, 3, 30, 51, 49]\n",
      "Start training on these clients: [16, 171, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [98, 7, 100, 28, 146, 181, 87, 41, 142, 26, 97, 140, 118, 13, 153, 153, 48, 107, 83, 100, 172, 134, 144, 9, 188, 97, 117, 92, 9, 87, 166, 172, 140, 99, 185, 69, 109, 128, 90, 28, 150]\n",
      "Start training on these clients: [47, 40, 24, 53, 27, 46, 24, 14, 60, 18, 66, 49, 53]\n",
      "Start training on these clients: [151, 74, 4]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [33, 162, 41, 138, 189, 137, 26, 145, 109, 163, 109, 71, 96, 130, 137, 33, 28, 169, 94, 112, 111, 23, 85, 75, 137, 118, 131, 168, 91, 138, 59, 141, 131, 114, 177, 130, 80, 105, 137, 147]\n",
      "Start training on these clients: [77, 40, 5, 67, 31, 50, 36, 46, 30, 50, 11, 37]\n",
      "Start training on these clients: [74, 61, 61, 151, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [70, 142, 124, 161, 68, 170, 160, 138, 189, 26, 153, 39, 22, 145, 9, 79, 165, 169, 181, 52, 133, 91, 13, 83, 159, 154, 173, 119, 129, 84, 124, 91, 127, 23, 135, 180, 152, 109, 174, 98, 149]\n",
      "Start training on these clients: [57, 25, 56, 2, 5, 37, 51, 73, 30, 12, 8, 2]\n",
      "Start training on these clients: [171, 20, 61, 171]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [81, 144, 121, 111, 137, 69, 187, 176, 28, 146, 189, 91, 9, 155, 142, 107, 161, 52, 134, 116, 167, 149, 150, 155, 87, 188, 148, 147, 92, 170, 120, 170, 144, 118, 22, 135, 78, 157, 179, 78]\n",
      "Start training on these clients: [76, 25, 25, 62, 43, 47, 10, 18, 50, 42, 47, 42]\n",
      "Start training on these clients: [0, 82, 151, 151, 20]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [1, 142, 70, 176, 48, 97, 22, 143, 58, 121, 123, 87, 116, 172, 103, 32, 159, 79, 52, 170, 140, 176, 150, 143, 156, 26, 96, 32, 156, 189, 145, 166, 128, 71, 87, 105, 168, 86, 92]\n",
      "Start training on these clients: [54, 40, 40, 8, 62, 54, 27, 55, 35, 46, 49, 62, 38, 50, 50, 3]\n",
      "Start training on these clients: [132, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [180, 71, 111, 189, 110, 34, 95, 87, 131, 187, 64, 39, 176, 161, 167, 9, 147, 146, 64, 177, 145, 147, 184, 128, 170, 173, 150, 41, 172, 32, 153, 85, 153, 172, 84]\n",
      "Start training on these clients: [11, 12, 21, 11, 45, 57, 45, 3, 76, 49, 24, 53, 18, 47, 30, 27, 31]\n",
      "Start training on these clients: [61, 151, 132, 20, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [114, 181, 144, 161, 129, 64, 183, 87, 167, 160, 161, 87, 33, 64, 121, 121, 154, 160, 17, 133, 178, 138, 126, 141, 135, 180, 91, 111, 119, 140, 13, 139, 142, 71, 178, 161, 23, 78, 159, 41, 117]\n",
      "Start training on these clients: [40, 11, 18, 72, 72, 40, 15, 21, 66, 11]\n",
      "Start training on these clients: [44, 132, 61, 4, 61, 122]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [104, 1, 121, 182, 78, 172, 103, 159, 113, 155, 64, 169, 111, 75, 176, 116, 133, 186, 123, 104, 125, 1, 146, 173, 108, 32, 33, 137, 166, 183, 75, 135, 81, 96, 134, 69, 178, 189, 176]\n",
      "Start training on these clients: [18, 47, 38, 50, 53, 25, 57, 31, 72, 21, 56, 56, 31, 72, 46]\n",
      "Start training on these clients: [29, 151, 151]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [147, 125, 86, 155, 52, 9, 184, 137, 156, 180, 23, 63, 152, 165, 181, 169, 166, 153, 188, 94, 182, 93, 166, 93, 141, 102, 58, 83, 168, 157, 133, 68, 139, 186, 118, 165, 176, 150, 7, 112]\n",
      "Start training on these clients: [60, 31, 21, 53, 11, 43, 62, 66, 62, 8, 43]\n",
      "Start training on these clients: [16, 44, 0, 151, 20, 61]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [84, 144, 41, 39, 70, 17, 167, 83, 137, 174, 100, 117, 91, 91, 48, 80, 163, 28, 96, 13, 129, 28, 85, 167, 80, 170, 144, 131, 136, 33, 134, 156, 136, 23, 158, 120, 155, 64, 146, 93]\n",
      "Start training on these clients: [72, 65, 42, 54, 46, 50, 50, 11, 31, 49, 5, 15, 49]\n",
      "Start training on these clients: [29, 29, 171, 4]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [69, 103, 149, 117, 84, 145, 153, 136, 112, 162, 85, 136, 117, 118, 33, 147, 52, 159, 143, 99, 138, 59, 144, 182, 90, 101, 180, 157, 162, 59, 172, 138, 167, 167, 107]\n",
      "Start training on these clients: [73, 5, 11, 60, 3, 11, 27, 56, 24, 67, 47, 30, 73, 43, 14]\n",
      "Start training on these clients: [151, 171, 171, 122, 20, 61, 151]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [114, 104, 165, 121, 70, 1, 28, 166, 185, 78, 113, 111, 124, 105, 127, 166, 170, 99, 109, 157, 138, 84, 103, 88, 110, 156, 48, 107, 95, 120, 71, 124, 104, 140, 172, 90, 92, 127, 19]\n",
      "Start training on these clients: [67, 40, 15, 14, 66, 27, 53, 10, 66, 21, 25, 45, 65, 10, 35, 37]\n",
      "Start training on these clients: [171, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [133, 184, 172, 34, 88, 152, 177, 64, 141, 103, 166, 89, 161, 124, 93, 103, 7, 79, 110, 117, 95, 135, 39, 118, 19, 153, 137, 85, 32, 156, 124, 187, 101, 77, 188, 107, 128, 181, 89]\n",
      "Start training on these clients: [18, 40, 8, 45, 42, 25, 31, 21, 46, 65, 30, 10]\n",
      "Start training on these clients: [151, 20, 171, 4, 0, 4]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [133, 71, 23, 127, 93, 96, 7, 181, 110, 99, 116, 112, 33, 102, 119, 185, 133, 59, 121, 101, 179, 120, 156, 114, 113, 161, 75, 150, 168, 170, 182, 140, 147, 28, 120, 19, 48, 2, 55, 89, 125, 184]\n",
      "Start training on these clients: [25, 30, 5, 11, 27, 62, 65, 11, 24, 30, 30]\n",
      "Start training on these clients: [4, 4, 20, 82]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [87, 13, 123, 188, 48, 156, 110, 129, 22, 26, 81, 39, 91, 118, 59, 125, 13, 179, 179, 177, 134, 28, 154, 159, 133, 188, 32, 101, 162, 92, 126, 77, 143, 120, 173, 90, 159, 36, 131, 140, 174, 139, 125, 68, 22]\n",
      "Start training on these clients: [31, 57, 30, 30, 50, 42, 35, 49, 24]\n",
      "Start training on these clients: [0, 74, 4]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [174, 146, 129, 88, 180, 91, 188, 126, 159, 108, 106, 104, 87, 9, 100, 148, 115, 135, 162, 161, 187, 59, 93, 87, 22, 55, 158, 127, 70, 12, 102, 188, 92, 123, 176, 70, 187, 139, 173, 36]\n",
      "Start training on these clients: [24, 50, 3, 53, 27, 49, 53]\n",
      "Start training on these clients: [4, 29, 0, 16, 82, 82, 171, 44, 20, 151]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [150, 58, 22, 59, 172, 19, 85, 72, 161, 51, 32, 98, 48, 109, 108, 68, 58, 22, 128, 183, 36, 70, 112, 23, 162, 96, 85, 177, 124, 141, 118, 169, 1, 23, 143, 185, 187, 103, 162, 161, 158, 173, 129, 32, 76, 70, 162]\n",
      "Start training on these clients: [18, 11, 65, 35, 56, 42, 35]\n",
      "Start training on these clients: [44, 74, 82]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [69, 84, 101, 43, 101, 142, 9, 182, 64, 87, 130, 111, 83, 98, 112, 96, 83, 124, 148, 169, 119, 169, 98, 113, 120, 99, 1, 84, 184, 51, 78, 104, 109, 95, 165, 110, 123, 123, 178, 12, 142, 118]\n",
      "Start training on these clients: [30, 35, 24, 3, 18, 10, 8, 27, 21, 67, 3, 45]\n",
      "Start training on these clients: [0, 74, 82]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [167, 180, 109, 134, 52, 12, 153, 101, 137, 142, 128, 38, 140, 175, 116, 162, 124, 126, 125, 157, 108, 90, 110, 81, 182, 51, 63, 101, 179, 34, 186, 120, 47, 168, 103, 28, 60, 94, 157, 90, 133, 99, 163, 165, 115, 174, 159]\n",
      "Start training on these clients: [24, 8, 53, 25, 62, 42, 25]\n",
      "Start training on these clients: [44, 132, 61]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [7, 104, 68, 39, 105, 140, 15, 94, 64, 110, 137, 120, 188, 162, 164, 58, 182, 69, 93, 181, 103, 124, 175, 112, 98, 17, 64, 59, 168, 55, 26, 9, 15, 150, 109, 183, 140, 141, 107, 180, 101, 109, 183, 148, 125, 177, 177, 183, 135]\n",
      "Start training on these clients: [24, 25, 67, 11]\n",
      "Start training on these clients: [122, 29, 122, 6]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [159, 28, 90, 162, 83, 91, 145, 60, 141, 166, 84, 189, 152, 39, 93, 92, 79, 129, 97, 91, 105, 93, 178, 160, 47, 84, 39, 156, 32, 64, 63, 2, 114, 37, 68, 84, 125, 142, 93, 48, 93, 139, 26, 36, 150, 47, 166]\n",
      "Start training on these clients: [49, 57, 67, 57, 49, 31]\n",
      "Start training on these clients: [46, 46, 122, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [180, 80, 106, 155, 152, 116, 73, 131, 187, 97, 138, 9, 119, 37, 78, 104, 102, 114, 169, 127, 175, 104, 143, 13, 111, 79, 183, 77, 112, 156, 155, 106, 131, 181, 81, 9, 169, 186, 153, 13, 179, 33, 48, 140, 104]\n",
      "Start training on these clients: [18, 45, 35, 49, 24, 56, 24, 65, 11]\n",
      "Start training on these clients: [0, 46, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [134, 159, 187, 125, 134, 85, 111, 7, 138, 126, 98, 120, 51, 107, 182, 174, 135, 1, 108, 36, 14, 9, 71, 152, 12, 43, 136, 116, 117, 115, 58, 141, 108, 58, 111, 133, 51, 124, 22, 188, 164, 163, 165, 186, 143, 71, 36, 1, 59]\n",
      "Start training on these clients: [42, 25, 50, 35]\n",
      "Start training on these clients: [29, 132, 66, 20]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [28, 134, 95, 68, 34, 120, 70, 163, 164, 105, 179, 70, 146, 138, 91, 109, 100, 12, 88, 130, 47, 107, 32, 47, 150, 144, 98, 69, 76, 149, 129, 117, 17, 96, 137, 160, 163, 43, 13, 83, 19, 180, 183, 32, 13, 15, 12]\n",
      "Start training on these clients: [65, 3, 8, 35, 45, 42, 57, 24]\n",
      "Start training on these clients: [132, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [187, 157, 147, 91, 105, 38, 146, 101, 147, 178, 152, 99, 93, 22, 125, 143, 116, 100, 181, 165, 68, 124, 41, 187, 85, 92, 156, 72, 141, 136, 36, 54, 100, 12, 114, 86, 140, 136, 75, 176, 89, 60, 60, 9]\n",
      "Start training on these clients: [10, 21, 67, 25, 42]\n",
      "Start training on these clients: [44, 122, 82, 46, 151, 44, 46, 151]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [116, 38, 111, 113, 41, 117, 121, 105, 183, 112, 100, 175, 114, 139, 106, 109, 133, 165, 33, 59, 105, 133, 163, 189, 120, 72, 164, 166, 38, 37, 188, 130, 108, 145, 55, 17, 68, 123, 144, 130, 140, 182]\n",
      "Start training on these clients: [11, 21, 18, 8, 10, 31, 8, 57, 49, 3, 62]\n",
      "Start training on these clients: [151, 20, 132, 74]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [23, 85, 86, 136, 26, 5, 140, 117, 64, 2, 121, 139, 127, 165, 162, 126, 63, 63, 175, 147, 146, 133, 48, 92, 177, 55, 154, 175, 107, 136, 143, 68, 98, 147, 88, 168, 141, 146, 105, 140, 100, 14, 153, 126, 129, 22, 188, 169]\n",
      "Start training on these clients: [10, 35, 62, 65, 31]\n",
      "Start training on these clients: [27, 46, 0, 44]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [177, 182, 78, 134, 147, 105, 51, 23, 141, 2, 92, 9, 172, 179, 187, 162, 112, 182, 78, 174, 158, 181, 37, 43, 108, 9, 137, 33, 118, 40, 81, 123, 108, 26, 106, 133, 60, 107, 172, 28, 164, 17, 184, 5]\n",
      "Start training on these clients: [42, 62, 56]\n",
      "Start training on these clients: [29, 74, 74, 132, 132, 151, 122, 66, 66, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [157, 127, 103, 105, 84, 121, 88, 130, 112, 117, 128, 128, 71, 109, 85, 51, 147, 71, 134, 99, 15, 81, 185, 158, 1, 101, 84, 150, 156, 125, 185, 154, 32, 52, 32, 100, 189, 171, 55, 1, 59, 100, 76, 158, 175, 97, 135, 116, 76, 2, 68]\n",
      "Start training on these clients: [57, 53, 35, 53]\n",
      "Start training on these clients: [66, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [143, 40, 95, 78, 72, 52, 167, 130, 162, 79, 61, 153, 115, 158, 7, 188, 113, 154, 118, 9, 180, 147, 79, 68, 87, 136, 41, 121, 7, 96, 79, 183, 23, 188, 176, 96, 103, 172, 189, 184, 188, 78, 32, 142, 17, 54]\n",
      "Start training on these clients: [8, 35, 42, 50, 11, 11]\n",
      "Start training on these clients: [16, 66, 27, 122, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [156, 55, 162, 141, 26, 116, 9, 180, 155, 19, 112, 167, 73, 108, 123, 109, 182, 2, 59, 52, 160, 112, 112, 155, 91, 173, 120, 17, 146, 125, 117, 172, 163, 84, 136, 156, 71, 133, 32, 84, 168, 152, 75, 141, 142, 159, 98, 61, 54]\n",
      "Start training on these clients: [11, 42, 25, 25, 10, 57]\n",
      "Start training on these clients: [30, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [61, 12, 104, 172, 146, 96, 113, 37, 142, 71, 177, 76, 116, 174, 118, 149, 83, 144, 119, 166, 48, 54, 114, 39, 116, 47, 176, 15, 161, 79, 36, 168, 87, 60, 156, 175, 177, 147, 155, 13, 91, 184, 128, 78, 68, 71, 61, 68]\n",
      "Start training on these clients: [24, 21, 8, 10, 62, 11, 62]\n",
      "Start training on these clients: [46, 30]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [109, 92, 183, 113, 14, 183, 125, 144, 114, 124, 140, 187, 138, 115, 167, 81, 166, 148, 139, 146, 120, 91, 69, 137, 14, 94, 28, 87, 69, 158, 43, 164, 94, 48, 146, 97, 39, 2, 9, 38, 111, 147, 59, 102, 76, 32, 98, 41]\n",
      "Start training on these clients: [8, 65, 50, 50, 21, 42]\n",
      "Start training on these clients: [0, 30, 46]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [101, 170, 41, 96, 54, 161, 134, 5, 69, 88, 59, 12, 4, 125, 39, 184, 75, 86, 106, 175, 162, 184, 157, 94, 104, 54, 76, 97, 172, 100, 97, 104, 71, 60, 182, 110, 75, 166, 5, 110, 26, 120, 183, 58]\n",
      "Start training on these clients: [8, 65, 65, 10, 21, 24, 49, 8]\n",
      "Start training on these clients: [46, 132, 16, 27, 46]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [115, 23, 86, 7, 159, 43, 20, 5, 156, 182, 156, 127, 52, 158, 170, 60, 110, 61, 107, 80, 176, 114, 75, 106, 137, 135, 160, 73, 170, 149, 101, 60, 160, 75, 100, 82, 99, 181, 37, 130, 86, 165, 106, 188, 164, 139, 188, 84, 143, 113, 75, 136]\n",
      "Start training on these clients: [62, 62]\n",
      "Start training on these clients: [44, 29, 30]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [150, 55, 2, 71, 68, 93, 22, 118, 71, 138, 176, 81, 54, 89, 47, 39, 145, 52, 130, 20, 123, 155, 145, 163, 186, 165, 154, 5, 165, 180, 169, 28, 20, 73, 75, 34, 98, 81, 130, 32, 113, 20, 20, 77, 89, 119, 91, 83, 165]\n",
      "Start training on these clients: [62, 45, 65, 57, 65]\n",
      "Start training on these clients: [30, 30, 44]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [101, 183, 34, 4, 73, 118, 165, 160, 144, 108, 75, 160, 41, 172, 172, 32, 121, 75, 125, 104, 146, 73, 82, 39, 152, 152, 175, 130, 15, 54, 127, 154, 164, 97, 123, 151, 93, 120, 176, 138, 97, 47, 188, 129, 146, 162, 119]\n",
      "Start training on these clients: [21, 45, 49, 56, 10, 49]\n",
      "Start training on these clients: [122, 46, 122, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [38, 40, 125, 189, 94, 121, 178, 138, 104, 78, 43, 135, 184, 77, 2, 102, 4, 144, 89, 148, 128, 32, 99, 160, 101, 7, 127, 68, 41, 173, 93, 156, 145, 83, 179, 175, 81, 95, 136, 176, 153, 136, 43, 71, 52, 182]\n",
      "Start training on these clients: [67, 35, 18, 67, 56, 65, 67, 53]\n",
      "Start training on these clients: [27, 132, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [163, 161, 139, 154, 38, 171, 52, 140, 4, 5, 78, 169, 146, 95, 82, 179, 9, 105, 100, 177, 88, 43, 143, 162, 140, 182, 78, 22, 9, 148, 19, 174, 159, 110, 169, 176, 183, 100, 145, 41, 174, 128, 61]\n",
      "Start training on these clients: [10, 24, 24, 3, 8, 3, 57, 49, 31]\n",
      "Start training on these clients: [66, 132, 46, 46, 46]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [82, 77, 61, 164, 83, 85, 124, 4, 95, 174, 20, 47, 26, 156, 131, 181, 2, 173, 22, 185, 13, 117, 26, 107, 84, 68, 116, 179, 139, 177, 99, 176, 72, 109, 167, 166, 143, 134, 2, 96, 133, 87, 173, 156, 180, 169, 103]\n",
      "Start training on these clients: [11, 65, 49, 21, 65, 11]\n",
      "Start training on these clients: [16, 66, 16, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [147, 26, 129, 125, 121, 40, 17, 182, 183, 109, 175, 1, 162, 75, 9, 112, 182, 90, 167, 168, 179, 128, 147, 69, 139, 141, 145, 181, 28, 20, 180, 123, 40, 69, 83, 89, 112, 77, 22, 92, 152, 52, 186, 48, 9, 146]\n",
      "Start training on these clients: [57, 24, 24, 57, 24, 45, 11]\n",
      "Start training on these clients: [27, 66, 66, 30]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [160, 110, 131, 133, 117, 4, 37, 186, 176, 69, 13, 81, 167, 155, 111, 92, 9, 130, 134, 137, 186, 12, 36, 52, 114, 182, 111, 176, 77, 155, 72, 112, 5, 84, 109, 179, 6, 145, 163, 167, 63, 133, 68, 84, 59, 115, 84, 170, 47, 146, 75, 154]\n",
      "Start training on these clients: [42, 25]\n",
      "Start training on these clients: [16, 46, 30]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [48, 96, 174, 168, 113, 97, 100, 145, 176, 98, 109, 144, 152, 148, 106, 117, 1, 4, 146, 72, 37, 175, 34, 93, 127, 112, 71, 100, 51, 23, 113, 144, 22, 143, 7, 9, 136, 74, 13, 138, 76, 170, 94, 84, 17, 125, 69, 63, 26, 175, 47, 78]\n",
      "Start training on these clients: [67, 8]\n",
      "Start training on these clients: [0, 29, 27]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [6, 173, 83, 113, 119, 183, 47, 154, 182, 58, 138, 165, 173, 187, 155, 115, 55, 144, 6, 115, 26, 102, 150, 116, 160, 38, 68, 157, 39, 148, 68, 92, 141, 186, 164, 189, 176, 103, 163, 157, 174, 144, 85]\n",
      "Start training on these clients: [21, 42, 50, 57, 35, 25, 21, 8, 67, 24, 53]\n",
      "Start training on these clients: [0, 30, 16]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [107, 33, 186, 41, 96, 58, 128, 41, 109, 96, 127, 181, 131, 180, 112, 13, 106, 161, 63, 17, 115, 135, 95, 162, 84, 68, 101, 116, 137, 119, 58, 41, 159, 166, 149, 97, 163, 5, 147, 121, 82, 160, 107, 146, 70, 152, 167, 36, 145]\n",
      "Start training on these clients: [11, 31, 24, 56]\n",
      "Start training on these clients: [0, 27, 29, 44]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [137, 92, 104, 82, 98, 169, 151, 9, 89, 186, 69, 2, 188, 114, 151, 2, 37, 155, 77, 120, 174, 177, 110, 181, 185, 119, 121, 121, 188, 48, 184, 2, 186, 36, 64, 125, 92, 110, 7, 116, 41, 108, 176, 119, 149]\n",
      "Start training on these clients: [65, 35, 67, 49, 57, 8]\n",
      "Start training on these clients: [27, 66, 46, 122, 0, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [68, 102, 115, 73, 95, 109, 36, 22, 148, 60, 71, 125, 176, 61, 125, 70, 108, 81, 176, 150, 161, 115, 39, 168, 136, 153, 60, 47, 153, 60, 81, 124, 75, 34, 92, 149, 60, 43, 81, 186, 134, 51, 70, 164, 148, 170, 188, 130]\n",
      "Start training on these clients: [21, 35, 11, 62, 65, 25, 35]\n",
      "Start training on these clients: [44, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [28, 159, 64, 51, 150, 131, 26, 58, 150, 86, 2, 177, 34, 115, 89, 179, 177, 83, 83, 12, 169, 17, 4, 41, 72, 70, 162, 58, 38, 52, 92, 80, 36, 41, 103, 80, 61, 87, 105, 70, 103, 187, 176, 133, 52]\n",
      "Start training on these clients: [18, 35, 57, 50, 62, 57, 56, 8]\n",
      "Start training on these clients: [46, 46, 29, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [68, 88, 134, 183, 98, 51, 120, 60, 83, 141, 145, 163, 115, 157, 114, 5, 70, 43, 118, 60, 110, 155, 145, 101, 13, 9, 168, 22, 166, 41, 103, 61, 9, 116, 43, 123, 109, 51, 79, 103]\n",
      "Start training on these clients: [10, 49, 50, 67, 62, 57, 49]\n",
      "Start training on these clients: [27, 29, 66, 46, 66, 27, 0, 27, 30, 27]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [144, 79, 177, 143, 93, 28, 77, 94, 64, 55, 9, 22, 116, 187, 48, 107, 59, 147, 121, 181, 91, 78, 166, 169, 7, 75, 140, 109, 107, 79, 52, 111, 147, 75, 17, 176, 51, 51, 144, 15, 77, 156, 107, 156, 159, 156, 127, 71, 186]\n",
      "Start training on these clients: [56, 49, 35, 24, 3, 57]\n",
      "Start training on these clients: [27, 132]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [39, 77, 73, 124, 130, 170, 39, 89, 142, 1, 160, 92, 152, 104, 189, 173, 144, 73, 133, 82, 149, 22, 161, 95, 48, 20, 109, 189, 146, 175, 145, 125, 112, 47, 61, 68, 43, 173, 94, 12, 159, 146, 81, 182, 151, 14]\n",
      "Start training on these clients: [62, 65, 49, 62, 49, 62, 11, 50]\n",
      "Start training on these clients: [66, 46, 46]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [15, 104, 184, 127, 179, 17, 118, 7, 58, 60, 15, 123, 75, 143, 124, 158, 188, 5, 59, 165, 188, 77, 75, 37, 172, 131, 123, 58, 154, 142, 13, 158, 69, 81, 161, 183, 139, 188, 101, 80, 20, 92, 187, 131, 69, 134, 110]\n",
      "Start training on these clients: [21, 21, 50, 35, 56, 57, 49, 25]\n",
      "Start training on these clients: [16, 44]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [41, 7, 135, 164, 1, 182, 182, 140, 32, 166, 83, 131, 34, 140, 160, 78, 138, 120, 93, 130, 54, 164, 143, 160, 129, 96, 58, 144, 159, 26, 101, 105, 15, 1, 41, 125, 146, 40, 155, 142, 81, 137, 144, 73, 103, 86, 13, 47, 151]\n",
      "Start training on these clients: [50, 11, 67, 57]\n",
      "Start training on these clients: [29, 66, 16, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [112, 155, 172, 92, 70, 70, 127, 12, 37, 130, 170, 151, 5, 15, 185, 2, 100, 104, 83, 58, 154, 141, 5, 38, 82, 149, 136, 96, 37, 91, 74, 184, 165, 136, 97, 90, 79, 136, 175, 73, 34, 9, 120, 37, 34]\n",
      "Start training on these clients: [31, 35, 67, 45, 57, 3, 11]\n",
      "Start training on these clients: [132, 66, 0, 132, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [13, 114, 2, 61, 48, 162, 76, 165, 91, 124, 77, 124, 52, 26, 37, 136, 95, 26, 76, 68, 165, 23, 137, 108, 98, 142, 97, 180, 19, 94, 166, 129, 173, 106, 155, 168, 48, 167, 121, 129, 55, 160, 40, 64, 76, 9, 138, 152, 51, 185, 124]\n",
      "Start training on these clients: [42, 3]\n",
      "Start training on these clients: [132, 30, 122, 0]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [68, 117, 183, 81, 83, 138, 88, 75, 106, 54, 130, 147, 58, 157, 93, 129, 69, 188, 58, 82, 26, 81, 48, 168, 109, 7, 84, 1, 73, 126, 171, 159, 81, 142, 188, 146, 163, 83, 105, 169, 15, 103, 116, 145, 101, 94, 22, 120, 170, 128]\n",
      "Start training on these clients: [65, 49, 18, 8]\n",
      "Start training on these clients: [30, 46, 30]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [52, 107, 134, 155, 86, 13, 157, 41, 6, 86, 14, 181, 141, 72, 156, 170, 163, 108, 1, 160, 32, 137, 5, 34, 145, 22, 52, 154, 107, 74, 130, 158, 100, 7, 36, 133, 140, 78, 36, 26, 68, 168, 87, 130, 13, 152, 182]\n",
      "Start training on these clients: [53, 42, 49, 24, 10, 35]\n",
      "Start training on these clients: [132, 29, 46, 66]\n",
      "len of nearest centroid:  3\n",
      "Start training on these clients: [142, 179, 99, 76, 140, 118, 131, 87, 165, 95, 2, 9, 36, 143, 98, 109, 5, 124, 131, 90, 15, 48, 146, 120, 17, 78, 129, 17, 72, 75, 102, 55, 73, 174, 123, 168, 180, 34, 5, 147, 70, 123, 1, 109, 4, 165, 185, 165]\n",
      "Start training on these clients: [3, 35, 31, 56, 24]\n",
      "Start training on these clients: [0, 132, 132, 46]\n",
      "accuracy: 0.454527, 10th percentile: 0.232857, 90th percentile 0.714286\n",
      "loss: 2.11462, 10th percentile: 1.32147, 90th percentile 2.83611\n",
      "microf1: 0.454527, 10th percentile: 0.232857, 90th percentile 0.714286\n",
      "macrof1: 0.306292, 10th percentile: 0.136798, 90th percentile 0.516071\n",
      "accuracy: 0.664114, 10th percentile: 0.591351, 90th percentile 0.754412\n",
      "loss: 1.18712, 10th percentile: 0.898286, 90th percentile 1.49626\n",
      "microf1: 0.664114, 10th percentile: 0.591351, 90th percentile 0.754412\n",
      "macrof1: 0.523748, 10th percentile: 0.454841, 90th percentile 0.597207\n",
      "accuracy: 0.63958, 10th percentile: 0.46875, 90th percentile 0.724359\n",
      "loss: 1.35204, 10th percentile: 1.17703, 90th percentile 2.12498\n",
      "microf1: 0.63958, 10th percentile: 0.46875, 90th percentile 0.724359\n",
      "macrof1: 0.475847, 10th percentile: 0.312121, 90th percentile 0.507407\n",
      "--- Acc:  0.5860736556628523  ---\n",
      "experiment of Fed Robust is finished.\n",
      "[50.]\n"
     ]
    }
   ],
   "source": [
    "!/home/jupyter/dev/mlenv/bin/python experiment.py -experiment fedrobust -dataset femnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c7498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m78"
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
